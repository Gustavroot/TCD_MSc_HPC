%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Short Sectioned Assignment
% LaTeX Template
% Version 1.0 (5/5/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Frits Wenneker (http://www.howtotex.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[paper=a4, fontsize=11pt]{scrartcl} % A4 paper and 11pt font size

\usepackage{listings}

\usepackage{verbatim}
\usepackage{textcomp}
\usepackage{changepage}
\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs
\usepackage{fourier} % Use the Adobe Utopia font for the document - comment this line to return to the LaTeX default
\usepackage{forest}
\usepackage[english]{babel} % English language/hyphenation
\usepackage{amsmath,amsfonts,amsthm} % Math packages

\usepackage{setspace}
\renewcommand{\baselinestretch}{1.3}
\usepackage{lipsum} % Used for inserting dummy 'Lorem ipsum' text into the template

\usepackage{color}

\usepackage{sectsty} % Allows customizing section commands
\allsectionsfont{\centering \normalfont\scshape} % Make all sections centered, the default font and small caps

\usepackage{fancyhdr} % Custom headers and footers
\pagestyle{fancyplain} % Makes all pages in the document conform to the custom headers and footers
\fancyhead{} % No page header - if you want one, create it in the same way as the footers below
\fancyfoot[L]{} % Empty left footer
\fancyfoot[C]{} % Empty center footer
\fancyfoot[R]{\thepage} % Page numbering for right footer
\renewcommand{\headrulewidth}{0pt} % Remove header underlines
\renewcommand{\footrulewidth}{0pt} % Remove footer underlines
\setlength{\headheight}{13.6pt} % Customize the height of the header

\numberwithin{equation}{section} % Number equations within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{figure}{section} % Number figures within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{table}{section} % Number tables within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)

\setlength\parindent{0pt} % Removes all indentation from paragraphs - comment this line for an assignment with lots of text

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\newcommand{\horrule}[1]{\rule{\linewidth}{#1}} % Create horizontal rule command with 1 argument of height

\title{	
\normalfont \normalsize 
%\textsc{TRINITY COLLEGE DUBLIN, school of Mathematics} \\ [25pt] % Your university, school and/or department name(s)
\horrule{0.5pt} \\[0.4cm] % Thin top horizontal rule
\huge Metropolis Algorithm \\ % The assignment title
\horrule{2pt} \\[0.5cm] % Thick bottom horizontal rule
}

\author{Gustavo Ramirez} % Your name

\date{\normalsize\today} % Today's date or a custom date

\begin{document}

\maketitle % Print the title

%----------------------------------------------------------------------------------------
%	PROBLEM 1
%----------------------------------------------------------------------------------------



A clear explanation to the Metropolis algorithm is developed here.




\newpage




The Metropolis algorithm is a way of sampling a p.d.f. $f(y)$ through the use of a Markov chain.

For the evolution of the chain, an auxiliar function is used, called the \textit{proposal function} $q(y)$. This proposal function, as is suggested by its name, proposes the next state of the chain for each iteration of the algorithm; therefore $y_{i} = q(y_{i-1})$. The whole set of values generated using $q(y)$ are distributed according to a p.d.f., let us say $f_{q}(y)$.

There is also another auxiliar p.d.f., the \textit{prior distribution} $\pi(y)$, which is selected generally such that $y_{0} = \pi(0)$. Just as for $q(y)$, the whole set of possible values generated with $\pi(y)$ are distributed according to a p.d.f., let us call it $f_{\pi}(y)$.

It is important to note that there may be different possible functions (or in this case, implementations) $q(y)$ generating the same p.d.f. $f_{q}(y)$, and the same applies for $\pi(y)$ and $f_{\pi}(y)$; but what is important is the form of the p.d.f.s $f_{q}(y)$ and $f_{\pi}(y)$.

Finally, the fundamental function to be sampled is called the \textit{target function} $f(y)$.

The algorithm is generally described through a series of steps. More descriptive features of both $f_{q}(y)$ and $f_{\pi}(y)$ will be given after the steps of the algorithm are listed. The term \textit{acceptance probability}, refering to how good is to take each new step in the chain proposed by the proposal function, will be explained as well after those steps.

\begin{enumerate}

\item generate $y_{0}$ using $\pi(y)$, set it as "current state" $y$ and add it to $\{ y_{i} \}$
\item keep in the following loop until necessary:

\begin{enumerate}

\item generate a proposal state $y^{*}$ using $q(y)$, and set it as "current state" $y$
\item calculate the acceptance probability:

\begin{equation}
\label{eq:MC_approx}
\alpha = \min\left( 1, \frac{f(y^{*})}{f(y)} \right)
%\begin{split}
%A & = \frac{\pi r^2}{2} \\
% & = \frac{1}{2} \pi r^2
%\end{split}
\end{equation}

\item generate a random number $u$, uniform over the interval $[0,1]$
\item if $u \le \alpha$, set $y^{*}$ as "current state" $y$ and add it to $\{ y_{i} \}$; if not, go back to step 2-(a)

\end{enumerate}

\end{enumerate}

In step 2, "until necessary" means until a desired accuracy (e.g. variance) is reached, until a number of steps is reached, etc.

Usually, when implementing the Metropolis algorithm, the form of $f(y)$ is fixed/given, and $f_{q}(y)$ and $f_{\pi}(y)$ are chosen such that the the output of the sampling, i.e. $\{ y_{i} \}$, meets certain characteristics. One of the nice characteristics of Markov chains, is that after a large number of steps, the system converges towards a fixed point, i.e. towards a fixed p.d.f.; in the case under consideration, 1-dim integrals and 1-dim p.d.f.s, this means that after a large number of steps, $\{ y_{i} \}$ is distributed according to $f(y)$. Here is where the term \textit{burn-in} comes in; burn-in is that initial subset of $\{ y_{i} \}$ which doesn't resemble that much to the target distribution $f(y)$.

If the burn-in is represented as $\{ y_{i}^{bi} \}$, then the set used in the Monte Carlo integration is $\{ y'_{i} \} = \{ y_{i} \} - \{ y^{bi}_{i} \} $; i.e. the summation in equation \ref{eq:MC_approx} is performed over the set $\{ y'_{i} \}$. How is the burn-in subset obtained? Usually $\{ y^{bi}_{i} \} = \{ y_{0}, y_{1}, ..., y_{49} \}$.


\end{document}